---
layout: post
title: Deploy com Beanstalk
subtitle: ML Drops v4
tags: [aws, mlops, beanstalk, deploy]
comments: true
draft: true
---

{: .box-note}
**Este é um texto em desenvolvimento**: Ainda estamos escrevendo e/ou revisando seu conteúdo. Até o dia de sua publicação, ele não estará listado na página inicial do blog.

Fala Galera!

No Drops de hoje, iremos abordar mais uma alternativa simples e direta de ***Deploy*** para nossos modelos de ***Machine Learning***.

Para mantermos o foco, que é justamente ser simples e direto, vamos utilizar o [AWS Beanstalk](https://aws.amazon.com/pt/elasticbeanstalk/). 

Durante a próxima sessão vamos entender quais facilidades o Beanstalk traz para o *deploy* de nossos modelos de Machine Learning.

## AWS Beanstalk

As facilidades mencionadas nas linhas acima, se dá ao fato de que o desenvolvedor enquanto está utilizando-se do Beanstalk, preocupa-se com o que sabe fazer de melhor, que é **o código**.

Uma vez que o código de sua aplicação esteja finalizado do ponto de vista técnico, começa então o verdadeiro trabalho do Beanstalk.

A partir daqui, objetivos como:

* Provisionamento de Infraestrutura
* Autoscaling
* Balanceadores de Carga
* Monitorações e Health-Checks

ficam sob a responsabilidade do Beanstalk.

Reforçando, mais uma vez, que o desenvolvedor preocupa-se apenas com o principal ativo técnico que será produzido, o código.

Uma coisa é certa pessoal, o Beanstalk sempre terá a missão de facilitar o *deploy* de sua aplicação, abstraindo e gerenciando atividades como: monitoração, Balanceamento, Autoscaling, etc.

Então, se é tão fácil... Por que não ?

## O Que faremos ?

Bom pessoal, para este Drops iremos realizar o ***deploy*** de um modelo de Machine Learning utilizando o AWS Beanstalk.

Tal modelo terá como objetivo analisar sentimento de textos. Utilizaremos um [dataset com reviews de celulares adquiridos na Amazon](https://www.kaggle.com/grikomsn/amazon-cell-phones-reviews).

Estes reviews serão classificados em três categorias: `positivo`, `negativo` ou `neutro`.

Já deu pra perceber que o nosso modelo se utilizará do que é comumente conhecido como [NLP](https://pt.wikipedia.o.rg/wiki/Processamento_de_linguagem_natural).

Para realizarmos tal processamento utilizaremos uma biblioteca bastante conhecida para análise de sentimentos em textos, a [Vader](https://pypi.org/project/vaderSentiment/).

Bom pessoal, o objetivo aqui não é adentrar nos conceitos matemáticos e léxicos que esta biblioteca implementa, porém, no final deste Drops irei colocar alguns links de referência para quem quiser saber mais sobre esta biblioteca.

Junto com o Vader, vamos precisar também de um servidor web que ira expor nosso modelo através de uma API.

Sem novidades. Flask, eu escolho você!

## Talk is Cheap, show me the Code!

Iniciamos criando o arquivo `application.py`, este script será responsável por realizar a predição do texto e também expor uma rota (GET e POST) chamada `/endpoint`, cujo o payload serão os textos das nossas reviews.

```python
# application.py

from flask import Flask, request, jsonify
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer

# Instanciando o objeto do analisador de sentimentos
reviews_analyzer = SentimentIntensityAnalyzer()

# Inicializando Flask aplication
application = Flask(__name__)

def sentiment_analyzer(text_review):
    
    text_review_sentiment = ''

    # Obtendo propriedades e score da review
    sentiment_properties = reviews_analyzer.polarity_scores(text_review)

    # Classificando a review de acordo com o compound score
    if sentiment_properties['compound'] >= 0.05:
        text_review_sentiment = 'Positivo'
    elif sentiment_properties['compound'] <= -0.05:
        text_review_sentiment = 'Negativo'
    else:
        text_review_sentiment = 'Neutro'
    return(text_review_sentiment)

# Criando uma rota GET e POST para consumo do nosso modelo

@application.route("/endpoint", methods=['GET','POST'])
def sentiment_endpoint():
    if request.method == 'POST':
        json_dict = request.get_json()
        if 'review_text' in json_dict:
            result = sentiment_analyzer(json_dict['review_text'])
            return jsonify({'output' : result})
        else:
            return jsonify({
                "status": "failed",
                "message": "parametro review_text vazio"
            })
    # Review passada por querystring
    if request.method == 'GET':
        review_text = request.args.get('review_text')
        result = sentiment_analyzer(review_text)
    
    return jsonify({'output' : result})

if __name__=='__main__':
    application.run()
```

O código em si é bem simples pessoal, basicamente temos dois métodos:

* `sentiment_analyzer` - Recebe o texto da nossa review por parâmetro e repassa ao Vader, obtendo assim o score de intensidade de sentimento para nosso texto. Repare que a utilização dele é bem simples, realizamos apenas um *import* e instanciamos a classe `SentimentIntensityAnalyzer`. Por fim, obtemos as nossas pontuações retornadas no método `polarity_scores` e realizamos a classificação em `Positivo`,`Negativo` ou `Neutro`.

* `sentiment_endpoint` - Expõe a rota `/endpoint` com os métodos GET / POST e também recebe como input o texto a ser analisado.

Com o código pronto, partimos para o deploy do nosso classificador utilizando o **Beanstalk**. Para este Drops, vamos utilizar o console da AWS.

## E as Dependências ?

Caso você esteja seguindo este Drops em um ambiente virtual (Anaconda, pyenv etc.), execute o comando:

```bash
pip freeze > requirements.txt
```

Como este comando, o arquivo `requirements.txt` será criado com todas as bibliotecas/dependências utilizadas no ambiente virtual durante o desenvolvimento do projeto.

Com os arquivos `application.py` e `requirements.txt` no mesmo diretório, criamos um arquivo zip com ambos os arquivos.

Não coloque estes arquivos dentro de subdiretórios/subpastas, pois o Beanstalk não conseguirá achá-los, os mesmos devem ficar na raíz do diretório.

## Deploy e Testes

Iniciamos acessando o console da AWS e selecionamos Beanstalk :

<p style="text-align: center"><img src="https://i.imgur.com/EtR5wAt.png"></p>

Na página seguinte, clicamos em **Create a new envrionment**


<p style="text-align: center"><img src="https://i.imgur.com/yi6ty2J.png"></p>

Vamos preencher os dados da nossa aplicação conforme imagem abaixo:

**Application Name**  - Nome de Nossa aplicação.

**Platform** - Informações referente a **runtime** de nossa aplicação, como por exemplo : Linguagem, Qual tipo de imagem/versao, etc.

**Application Code** - Em nosso exemplo vamos realizar o upload do arquivo **.zip** contendo o código e as depêndencias, selecione a opção *Upload your Code*.

**Source Code Origin** - Nesta seção vamos escolher um nome para a versão da nossa aplicação, bem como informar o local de armazenamento doa arquivo **.zip**.


<p style="text-align: center"><img src="https://i.imgur.com/HU8XZBk.jpg"></p>

Após o preenchimento das informações acima, em cerca de 5 a 10 minutos, o ambiente será provisionado e uma URL será disponibilizada para consumo.

<p style="text-align: center"><img src="https://i.imgur.com/LJb4RnN.png"></p>

Para facilitar o teste, vamos pegar uma *review* aletória do *dataset* que estamos utilizando e consumir o modelo via GET, passando nossa *review* por *querystring* e recebendo o resultado de nossa predição: `Positivo`,`Neutro` ou `Negativo`.

```bash
curl "http://analyzersentiment-env.eba-3vcgtsyv.us-east-1.elasticbeanstalk.com/endpoint?review_text=\n
Good phone...good price.,This was a replacement for the one my mom had that went south \n
 on us. Can't really complain about it because the problem with \n
 this device is the carrier not the phone. Probably should give \n
 it five stars because the seller gave a spot on description, \n  
 gave a charger, and threw in a case for free but yet again my \n
  carrier doesn't seem to like the phone. I did receive this package next day."
```

Resultado de nossa predição:

```bash
{"output":"Positivo"}
```

Excelente! Conseguimos realizar a análise de sentimento para este texto (e para tantos outros que estão presentes neste dataset). 

Valeu, Beanstalk!

## Pensamentos Finais

Conseguimos, mais uma vez, disponibilizar uma alternativa para deploy de Modelos de Machine Learning ao nosso cliente final.

Este é apenas um exemplo, porém, já é possível perceber que a partir desse pontapé inicial consegurimos evoluir nossa arquitetura e utilizar o Beanstalk como mais uma opção em nossa prateleira de produtos.

Até o próximo Drops!

## Refêrencias

* [Vader](https://pypi.org/project/vaderSentiment/)
* [AWS Beanstalk](https://aws.amazon.com/pt/elasticbeanstalk/)