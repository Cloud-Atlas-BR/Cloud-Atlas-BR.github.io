---
layout: post
title: Deploy com Beanstalk
subtitle: ML Drops v3
tags: [aws, mlops, sagemaker, deploy, log]
comments: true
draft: true
---

{: .box-note}
**Este é um texto em desenvolvimento**: Ainda estamos escrevendo e/ou revisando seu conteúdo. Até o dia de sua publicação, ele não estará listado na página inicial do blog.

Fala Galera!

No Drops de hoje iremos abordar mais uma alternativa simples e direta de ***Deploy*** para nossos modelos de ***Machine Learning***.

Para mantermos o foco, que é justamente ser simples e direto, vamos utilizar o [AWS Beanstalk](https://aws.amazon.com/pt/elasticbeanstalk/). 

O principal objetivo deste serviço, é facilitar o desenvolvimento e a implantação de aplicações voltadas ao ambiente Web.

## AWS Beanstalk

A facilidade relatada nas linhas acima, se dá ao fato de que o desenvolvedor enquanto esta utilizando-se do Beanstalk preocupa-se com o que sabe fazer de melhor, que é **o código**.

Uma vez que o código de sua aplicação esteja finalizado do ponto de vista técnico, começa então o verdadeiro trabalho do Beanstalk.

A partir daqui, objetivos como:

* Provisionamento de Infraestrutura
* Autoscaling
* Balanceadores de Carga
* Monitorações e Health-Checks

Ficam sob a responsabilidade do Beanstalk todas estas etapas, reforçando mais uma vez que o desenvolvedor preocupa-se apenas com o principal ativo técnico que será produzido, o código

## O Que faremos ?

Bom pessoal, para este drops iremos realizar o ***deploy*** de um modelo de Machine Leanrning utilizando o `AWS Beanstalk`.

Tal modelo terá como objetivo analisar sentimento de textos. Utilizaremos um [dataset](https://www.kaggle.com/grikomsn/amazon-cell-phones-reviews) com reviews de celulares adquiridos na `Amazon`.

Estes reviews serão classificados em três categorias : `positivo`, `negativo` ou `neutro`.

Já deu pra perceber que o nosso modelo se utilizará do que é comumente conhecido como [NLP](https://pt.wikipedia.o.rg/wiki/Processamento_de_linguagem_natural).

Para realizarmos tal processamento utilizaremos uma biblioteca bastante conhecida para análise de sentimentos em textos, o [Vader](https://pypi.org/project/vaderSentiment/).

Bom pessoal, o objetivo aqui não é adentrar nos conceitos matemáticos e léxicos que esta biblioteca implementa, porém, no final deste drops irei colocar alguns links de referência para quem quiser saber mais sobre esta biblioteca.

Junto com o `Vader`, vamos precisar também de um servidor web que ira expor nosso modelo através de uma API.

Sem novidades, Flask ! Eu escolho você !

## Talk is Cheap, show me the Code !

Iniciamos criando o arquivo `application.py`, este script será responsável por realizar a predição do texto e também expor uma rota (GET e POST) `/endpoint` cujo o payload serão os textos das nossas reviews.

`application.py`
```python
from flask import Flask, request, jsonify
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer

#Instanciando o objeto do analisador de sentimentos
reviews_analyzer = SentimentIntensityAnalyzer()

#inicializando Flask aaplication
application = Flask(__name__)

def sentiment_analyzer(text_review):
    
    text_review_sentiment = ''

    #Obtendo  propriedades e score da review
    sentiment_properties = reviews_analyzer.polarity_scores(text_review)

    #Classificando a review de acordo com o compound score
    if sentiment_properties['compound'] >= 0.05:
        text_review_sentiment = 'Positivo'

    elif sentiment_properties['compound'] <= -0.05:
        text_review_sentiment = 'Negativo'
    else:
        text_review_sentiment = 'Neutro'

    return(text_review_sentiment)

#Criando uma rota GET e POST para consumo do nosso modelo
@application.route("/endpoint", methods=['GET','POST'])
def sentiment_endpoint():
    if request.method == 'POST':
        json_dict = request.get_json()
        if 'review_text' in json_dict:
            result = sentiment_analyzer(json_dict['review_text'])
            return jsonify({'output' : result})
        else:
            return jsonify({
                "status": "failed",
                "message": "parametro review_text vazio"
            })
    #review passada por querystring
    if request.method == 'GET':
        review_text = request.args.get('review_text')
        result = sentiment_analyzer(review_text)
    
    return jsonify({'output' : result})

if __name__=='__main__':
    application.run()

```

O código em si é bem simples pessoal, basicamente temos dois metodos :

* `sentiment_analyzer` - Recebe o texto da nossa review por parâmetro e repassa ao `Vader`, obtendo assim o score de intensidade de sentimento para nosso texto. Repare que a utilização dele é bem simples, realizamos apenas um import e instanciamos a classe `SentimentIntensityAnalyzer`. Por fim, obtemos as nossas pontuações retornadas no método `polarity_scores` e realizamos a classificação em `Positivo`,`Negativo` ou `Neutro`.

* `sentiment_endpoint` - expõem a rota `/endpoint` com os métodos `GET` / `POST` e também recebe como input o texto a ser analisado.

Com o código pronto, partimos para o deploy do nosso classificador utilizando o `Beanstalk`, para este drops vamos utilizar o console da AWS.

## E as Dependências ?

Caso você esteja seguindo este drops em um ambiente virtual(Anaconda,pyenv,etc) rode o comando:
```bash
pip freeze
```
como este comando o arquivo `requirements.txt` será criado com todas as bibliotecas/dependências utilizadas no ambiente virtual durante o desenvolvimento do projeto.

Com os arquivos `application.py` e `requirements.txt` no mesmo diretório, criamos um .zip com os dois arquivos.

