---
layout: post
title: Captura de logs com Sagemaker Endpoints
subtitle: ML Drops v3
tags: [aws, mlops, sagemaker, deploy, log]
comments: true
draft: true
---

{: .box-note}
**Este é um texto em desenvolvimento**: Ainda estamos escrevendo e/ou revisando seu conteúdo. Até o dia de sua publicação, ele não estará listado na página inicial do blog.

Se engana o cientista de dados que acredita que seu trabalho está finalizado com o treinamento de um modelo, assim como o engenheiro de ML quando sobe o modelo para produção. O ciclo de vida de um modelo de machine learning é, literalmente, sem fim.

<center>
<blockquote class="imgur-embed-pub" lang="en" data-id="a/RBWQRTj"  ><a href="//imgur.com/a/RBWQRTj">O ciclo sem fim do Machine Learning</a></blockquote><script async src="//s.imgur.com/min/embed.js" charset="utf-8"></script>
</center>

Seja no início, no fim ou no meio, dados são uma importante força para esse ciclo continuar girando. 

Novas fontes de dados motivam a experimentação de diferentes abordagens por parte dos cientistas de dados, informações do mercado geram novos requisitos por parte das áreas de negócio e o **log dos modelos em produção orienta estratégias de recalibração, alarmes e alertas**.

Acompanhar o comportamento real do seu modelo, recebendo chamadas de sistemas e pessoas, é peça indispensável para que o ciclo de vida de um modelo seja **saudável**.

**Conhecer os consumidores do seu modelo** evita que o seu *output* seja consumido por outros sistemas sem que exista uma governança estabelecida. Isto também permite que estes consumidores possam ser alertados sobre mudanças com potencial geração de incidentes.

**Conhecer os dados que são enviados para seu modelo** para obtenção de predições nos permite avaliar se ele está sendo consumido para o uso que foi desenvolvido, e se ainda pode ser utilizado mesmo com alterações quantitativas e qualitativas dos dados ao longo do tempo.

Finalmente, **conhecer as respostas que seu modelo gera** nos dá insumos para avaliar enviesamentos, interpretar resultados e garantir que o modelo se comporta dentro de sua performance esperada.

Ufa!

Não faltam motivos para registrar e analisar os logs de seu modelo. Contudo, criar e manter a infraestrutura responsável por tal pode ser custoso.

Por esta razão, a AWS fornece uma conveniente *feature* junto com o serviço [Sagemaker Endpoints](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-deployment.html): *Data capture*.

## Sagemaker Endpoints

Os Sagemaker Endpoints são a solução de deploy de modelos online de Machine Learning da AWS. De forma resumida, se trata de um container Docker que expõe seu modelo na forma de um REST API. Toda a infraestrutura é gerenciada pela AWS, ficando a configuração do deploy sob responsabilidade da engenharia/cientista de dados.

<p style="text-align: center"><a href="https://aws.amazon.com/blogs/machine-learning/load-test-and-optimize-an-amazon-sagemaker-endpoint-using-automatic-scaling/"><img src="https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2018/05/17/load-test-sagemaker-3.gif"></a></p>

Para exemplificar o registro de logs dos Sagemaker Endpoints via *Data capture*, vamos criar e implantar um modelo de classificação a partir do *dataset* `iris`.

```python
import pandas as pd
from sklearn.datasets import load_iris

X, y = load_iris(return_X_y=True, as_frame=True)
dados = pd.concat([y, X], axis=1)
dados.to_csv("data/dados.csv", header=False, index=False)
```

Acima, carregamos os dados e escrevemos em disco o arquivo *csv* no formato esperado pelo Sagemaker.

Em seguida, enviamos os dados para um bucket S3 para uso do Sagemaker no treinamento do modelo.

```python
import sagemaker

bucket = sagemaker.Session().default_bucket()
input_data = sagemaker.Session().upload_data(path="data", bucket=bucket)
train_input = TrainingInput(input_data, content_type="csv")
```

Configuramos um modelo de XGBoost gerenciado pela AWS para o treinamento, com as seguintes linhas de código.

```python
import sagemaker
from sagemaker.estimator import Estimator

xgboost_container = sagemaker.image_uris.retrieve("xgboost", "us-east-1", "1.2-1")
role = sagemaker.get_execution_role() # Ou insira uma role que o Sagemaker possa assumir

hyperparameters = {
    "objective":"multi:softmax",
    "num_round":"2",
    "num_class": "3"
}

estimator = Estimator(image_uri=xgboost_container,
                      role=role,
                      hyperparameters=hyperparameters,
                      instance_count=1,
                      instance_type='ml.m5.2xlarge', 
                      volume_size=5,
                      output_path=f"s3://{bucket}")
```

Finalmente, treinamos nosso modelo executando:

```python
estimator.fit({'train': train_input})
```

Um retorno semelhante ao apresentado abaixo será apresentado em caso de sucesso.

```
2021-03-09 02:53:32 Starting - Starting the training job...
2021-03-09 02:53:56 Starting - Launching requested ML instancesProfilerReport-1615258411: InProgress
......
2021-03-09 02:54:57 Starting - Preparing the instances for training...
2021-03-09 02:55:37 Downloading - Downloading input data...
2021-03-09 02:55:57 Training - Downloading the training image......
INFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)
INFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode
INFO:root:Determined delimiter of CSV input is ','
INFO:root:Single node training.
INFO:root:Train matrix has 150 rows
[0]#011train-merror:0.04000
[1]#011train-merror:0.04000

2021-03-09 02:57:39 Completed - Training job completed
ProfilerReport-1615258411: NoIssuesFound
Training seconds: 120
Billable seconds: 120
```

A partir do objeto `estimator` podemos realizar o deploy de um sagemaker endpoint


