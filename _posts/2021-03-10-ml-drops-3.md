---
layout: post
title: MLflow e Sagemaker, juntos somos mais fortes.
subtitle: ML Drops v3
tags: [aws, mlops, cloudformation, iaac, iac]
comments: true
draft: true
---

Fala Galera!

No Drops de hoje, vamos falar sobre um assunto interessantíssimo, aprenderemos como utilizar em conjunto o [MLflow](https://mlflow.org/) e o [AWS Sagemaker](https://aws.amazon.com/pt/sagemaker/) para catalogação e ***Deploy*** dos nossos Modelos de Machine Learning.

Aqui, o protagonismo fica a cargo do [MLflow](https://mlflow.org/) cuja a responsabilidade é servir de registry central para nossos modelos, enquanto que o [AWS Sagemaker](https://aws.amazon.com/pt/sagemaker/) ficará responsável por expor um Endpoint de consumo para o modelo. Este serviço é conhecido como [AWS Sagemaker Endpoint](https://docs.aws.amazon.com/sagemaker/latest/dg/deploy-model.html).


O objetivo aqui é apresentar de forma didática e simples a parceria entre  [MLflow](https://mlflow.org/) e [AWS Sagemaker](https://aws.amazon.com/pt/sagemaker/). Mostraremos também os frutos dessa parceria através de uma implementação real de um modelo de Machine Learning utilizando esses dois serviços.


Let's Bora !

## Conhecendo o MLFlow

O [MLflow](https://mlflow.org/) é definido como uma plataforma open source para gerenciamento do ciclo de vida de um Modelo de Machine Learning.

<p style="text-align: center"><img src="https://i.imgur.com/aosrKdj.png?1"></p>


Partindo da questão Ciclo de Vida de um Modelo, o [MLflow](https://mlflow.org/) concentra suas funcionalidades em quatro principais componentes

* [MLflow Tracking](https://mlflow.org/docs/latest/tracking.html) - Monitoração de Modelos
* [MLflow Projects](https://mlflow.org/docs/latest/projects.html) - Garantia de reprodutibilidade e idempotencia do Modelo
* [MLflow Models](https://mlflow.org/docs/latest/models.html) - Produtização e Deploy
* [MLflow Model Registry](https://mlflow.org/docs/latest/model-registry.html)  - Repositório/Catalogo centralizado dos Modelos

Para o Drops de hoje iremos demonstrar a funcionalidade do quarto componente, o [MLflow Model Registry](https://mlflow.org/docs/latest/model-registry.html) 

A partir deste componente será possível centralizarmos nosso registry/catalogo de modelos, bem como gerencia-los através de API's, UI, etc.

Com nosso catalog/registry disponibilizado pelo [MLflow](https://mlflow.org/), partimos agora para a produtização dos nossos modelos previamente catalogados, para esta tarefa utilizaremos o [AWS Sagemaker](https://aws.amazon.com/pt/sagemaker/)

## Conhecendo o AWS Sagemaker Endpoint

Com o nosso modelo devidamente catalogado e armazenado em nosso registry, iniciamos a caminhada de disponibilizar o mesmo para consumo.

Para isso, utilizaremos o [AWS Sagemaker Endpoint](https://docs.aws.amazon.com/sagemaker/latest/dg/deploy-model.html). 

Antes de continuarmos pessoal, vale ressaltarmos que o [AWS Sagemaker](https://aws.amazon.com/pt/sagemaker/) possui uma stack de serviços muito extensa, que por si só teria conteúdo para uma série inteira, todinha pra ele.

De uma forma simples e direta o AWS Sagemaker Endpoint nos disponibiliza uma lista de instâncias genreciadas cujo o propósito será expor um endpoint com rotas de API especificas para consumo.

* `/invocation` - Rota que recebe o payload e transmite o mesmo ao modelo.
* `/ping` - Rota de health check.

Tais rotas terão como destino um container Docker, sendo que dentro deste container Docker o código do nosso modelo estará presente.

## Arquitetura 

Para termos um registro visual do que explicamos ate agora, apresento-lhes o desenho da arquitetura deste Drops.


<p style="text-align: center"><img src="https://i.imgur.com/2hTEFRz.jpg"></p>

O objetivo desta arquitetura é justamente implementar de forma rápida e simples o que foi apresentado até aqui.

Para atingirmos este objetivo, utilizaremos os seguintes recurso:

 * `AWS ECR` - Registry que ficará a nossa imagem Docker
 * `AWS Fargate` - Serviço AWS que disponibiliza o AWS ECS de forma serverless.
 * `AWS Sagemaker Endpoint` - serviço AWS responsável por expor o endpoint com nosso modelo de Machine Learning.

Bom, agora chega de blablablá e vamos para a ação.

## Let's Get Started

Iniciaremos configurando nosso servidor serverless do MLflow.

Como explicado anteriormente utilizaremos o [AWS Fargate](https://aws.amazon.com/pt/fargate), o mesmo tem como objetivo fornecer nosso [MLflow](https://https://mlflow.org/)  instanciado através de um container [Docker](https://www.docker.com/) em uma infraestrutura totalmente serverless.


 Abaixo temos o nosso Dockerfile referente ao MLflow:
 
