---
layout: post
title: Captura de logs com Sagemaker Endpoints
subtitle: ML Drops v3
tags: [aws, mlops, sagemaker, deploy, log]
comments: true
draft: true
---

{: .box-note}
**Este é um texto em desenvolvimento**: Ainda estamos escrevendo e/ou revisando seu conteúdo. Até o dia de sua publicação, ele não estará listado na página inicial do blog.

Se engana o cientista de dados que acredita que seu trabalho está finalizado com o treinamento de um modelo, assim como o engenheiro de ML quando sobe o modelo para produção. O ciclo de vida de um modelo de machine learning é, literalmente, sem fim.

<center>
<blockquote class="imgur-embed-pub" lang="en" data-id="a/RBWQRTj"  ><a href="//imgur.com/a/RBWQRTj">O ciclo sem fim do Machine Learning</a></blockquote><script async src="//s.imgur.com/min/embed.js" charset="utf-8"></script>
</center>

Seja no início, no fim ou no meio, dados são uma importante força para esse ciclo continuar girando. 

Novas fontes de dados motivam a experimentação de diferentes abordagens por parte dos cientistas de dados, informações do mercado geram novos requisitos por parte das áreas de negócio e o **log dos modelos em produção orienta estratégias de recalibração, alarmes e alertas**.

Acompanhar o comportamento real do seu modelo, recebendo chamadas de sistemas e pessoas, é peça indispensável para que o ciclo de vida de um modelo seja **saudável**.

**Conhecer os consumidores do seu modelo** evita que o seu *output* seja consumido por outros sistemas sem que exista uma governança estabelecida. Isto também permite que estes consumidores possam ser alertados sobre mudanças com potencial de quebra dos seus sistemas.

**Conhecer os dados que são enviados para seu modelo** para obtenção de predições nos permite avaliar se ele está sendo consumido para o uso que foi desenvolvido, e se ainda pode ser utilizado mesmo com alterações quantitativas e qualitativas dos dados ao longo do tempo.

**Conhecer a resposta 
