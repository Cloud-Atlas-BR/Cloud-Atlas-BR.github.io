---
layout: post
title: Reutilização de contexto de Funções Lambda
subtitle: ML Drops v2
tags: [aws, mlops, cloudformation, iaac, iac]
comments: true
draft: true
---

Fala Galera!

No Drops de hoje vamos falar sobre um assunto bem interessante, que apesar de não ser novo, muitas vezes passa desapercebido durante o desenvolvimento de aplicações *serverless*.

Quando falamos de arquiteturas *serverless* provavelmente uma das primeiras ferramentas que sempre aparecem como forte candidata de uso são as [funções Lambda](https://aws.amazon.com/pt/lambda/).

Devido ao grande poder de paralelismo, escalonamento e também alta disponibilidade, as funções `Lambda` sempre enchem os olhos quando estamos codando nossa aplicação/modelo.

Ainda assim com tantos benefícios, queremos mostrar uma alternativa de ganho de performance durante as execuções das funções Lambda.

## Instanciamento e Spawn

Quando executamos uma função `Lambda` pedimos de forma explicita para que a AWS nos disponibilize uma infraestrutura e também um container (gerenciado) que será responsável pela execução de nosso código.

Como falamos anteriormente, um dos benefícios de uma função `Lambda` é o seu poder de escalabilidade, então, podemos assumir que caso simulássemos um ambiente de múltiplas requisições à mesma função `Lambda`, diversas cópias/containers da mesma função seriam instanciadas.

<p style="text-align: center"><img src="https://i.imgur.com/YIINDjE.png"></p>

É comum possuirmos conexões a Bancos de Dados (RDS), buckets S3, filas SQS e outros serviços dentro de uma função lambda. Tais conexões aumentam o tempo de `runtime` das nossas funções, uma vez que as mesmas tem como objetivo fornecer uma experiência `stateful`.

Com isso, ao executarmos uma função `lambda` pela primeira vez, ou então, executarmos a mesma função depois de um período de inatividade, nos deparamos com o que a AWS chama de `cold start`.

## Cold Start e Reutilização de contexto

As etapas do processo de `cold start` de funções Lambda são:

* Download de dependências e do código da função
* Inicialização do container
* Execução do código da função lambda antes do handler
* Execução do handler da função lambda
  
O fluxo acima sempre irá ocorrer na primeira execução da função Lambda, porém, a medida que as funções são executadas de forma escalonada e paralelizada, a AWS prioriza a **otimização** dos seus recursos.

Ou seja, porque não reutilizarmos funções Lambda já instanciadas para novas execuções?

É essa otimização que a AWS realiza, a chamada *reutilização de contexto*.

Quando reutilizamos containers já instanciados, pulamos diretamente para o **quarto** passo do processo de `cold start`, que passa a ser conhecido como `warm start`.
  
O uso de `warm start` pode ser configurado diretamente no código fonte de nossa função `lambda`, garatindo que conexões/integrações que ocorreram durante o `cold start` serão reutilizadas (e.g. carregamento de .pkl, ou a conexão da base dados).

Para isso basta que as conexões/integrações estejam escritas **fora do método handler**, assim os contextos criados serão **reutilizadas** e não instanciados novamente.

Com esta modificação, garantimos uma redução no tempo de execução da nossa função sempre que o processo de **reutilização de contexto** estiver ativo. Por padrão, cada função lambda permanece em `warm start` por 15 minutos após a primeira execução.

<p style="text-align: center"><img src="https://i.imgur.com/OZliAry.jpg"></p>

## Bora pro Código

Vamos criar uma função Lambda com o seguinte código.

```python
import json
import boto3

def lambda_handler(event, context):
    
    s3 = boto3.client("s3")
    buckets = s3.list_buckets()
    
    return {
        'statusCode': 200,
        'body': json.dumps(buckets, default=str) 
    }
```

No código acima criamos uma conexão no s3 via boto3, e sem seguida listamos os buckets S3 em nossa conta.

Ao fazer a primeira chamada dessa função lambda, levou-se aproximadamente ~1,5 segundos. Já a segunda chamada durou ~400 ms. Um caso clássico dos efeitos do `cold start` e `warm start`.

<p style="text-align: center"><img src="https://i.imgur.com/1UZSE23.png"></p>
<p style="text-align: center; margin-top:0">Cold start da função lambda com código dentro do handler</p>

<p style="text-align: center"><img src="https://i.imgur.com/3R05WG8.png"></p>
<p style="text-align: center; margin-top:0">Warm start da função lambda com código dentro do handler</p>

Agora, alterando o código da função para que o contexto de conexão ao S3 esteja **fora** do *handler*.

```python
import json
import boto3

s3 = boto3.client("s3")
buckets = s3.list_buckets()

def lambda_handler(event, context):
        
    return {
        'statusCode': 200,
        'body': json.dumps(buckets, default=str) 
    }
```

Os resultados são impressionantes! A segunda chamada da função lambda fazendo a conexão com o S3 fora do *handler* durou apenas **1 ms**!!!

<p style="text-align: center"><img src="https://i.imgur.com/i0Y2g0R.png"></p>
<p style="text-align: center; margin-top:0">Warm start da função lambda com código fora do handler</p>

## Pensamentos finais

Conhecer as diferenças do `cold start` e do `warm start` fazem toda a diferença no uso de funções Lambda.

Pensando em termos de machine learning, onde modelos carregados podem ter tamanhos variando entre MB e GB, utilizar essa feature pode ser determinante na performance do deploy do seu modelo.

Até o próximo Drops!

## Referências

* [New for AWS Lambda – Predictable start-up times with Provisioned Concurrency](https://aws.amazon.com/blogs/compute/new-for-aws-lambda-predictable-start-up-times-with-provisioned-concurrency/)